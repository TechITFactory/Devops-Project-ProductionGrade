# Sprint 2, Story 4.3: Install Cluster Autoscaler

## Story Summary
Deploy Cluster Autoscaler to automatically scale node groups based on pod demand.

**What We're Installing:**
- Cluster Autoscaler deployment
- IRSA role for Autoscaler
- Autoscaling policies

---

## Prerequisites
- S4.1 completed (EKS cluster running)
- OIDC provider configured
- Node group tagged for autoscaler

---

## Part 1: Create IRSA Role for Cluster Autoscaler

### Step 1.1: Add to EKS Module (or create separate file)
```bash
cd ~/Desktop/Devops-Project/techitfactory-infra/modules/eks

cat >> main.tf << 'EOF'

# =============================================================================
# CLUSTER AUTOSCALER IRSA
# =============================================================================

resource "aws_iam_role" "cluster_autoscaler" {
  count = var.enable_cluster_autoscaler ? 1 : 0
  name  = "${local.cluster_name}-cluster-autoscaler"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Principal = {
        Federated = aws_iam_openid_connect_provider.cluster.arn
      }
      Action = "sts:AssumeRoleWithWebIdentity"
      Condition = {
        StringEquals = {
          "${local.oidc_issuer}:aud" = "sts.amazonaws.com"
          "${local.oidc_issuer}:sub" = "system:serviceaccount:kube-system:cluster-autoscaler"
        }
      }
    }]
  })

  tags = local.common_tags
}

resource "aws_iam_role_policy" "cluster_autoscaler" {
  count = var.enable_cluster_autoscaler ? 1 : 0
  name  = "cluster-autoscaler-policy"
  role  = aws_iam_role.cluster_autoscaler[0].id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "autoscaling:DescribeAutoScalingGroups",
          "autoscaling:DescribeAutoScalingInstances",
          "autoscaling:DescribeLaunchConfigurations",
          "autoscaling:DescribeScalingActivities",
          "autoscaling:DescribeTags",
          "ec2:DescribeInstanceTypes",
          "ec2:DescribeLaunchTemplateVersions",
          "ec2:DescribeImages",
          "ec2:GetInstanceTypesFromInstanceRequirements",
          "eks:DescribeNodegroup"
        ]
        Resource = "*"
      },
      {
        Effect = "Allow"
        Action = [
          "autoscaling:SetDesiredCapacity",
          "autoscaling:TerminateInstanceInAutoScalingGroup"
        ]
        Resource = "*"
        Condition = {
          StringEquals = {
            "aws:ResourceTag/k8s.io/cluster-autoscaler/${local.cluster_name}" = "owned"
          }
        }
      }
    ]
  })
}
EOF

# Add output
cat >> outputs.tf << 'EOF'

output "cluster_autoscaler_role_arn" {
  description = "IAM role ARN for Cluster Autoscaler"
  value       = var.enable_cluster_autoscaler ? aws_iam_role.cluster_autoscaler[0].arn : null
}
EOF
```

### Step 1.2: Apply Terraform
```bash
cd ~/Desktop/Devops-Project/techitfactory-infra/environments/dev
terraform apply
```

---

## Part 2: Deploy Cluster Autoscaler

### Step 2.1: Create Service Account
```bash
kubectl apply -f - <<EOF
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  annotations:
    eks.amazonaws.com/role-arn: $(terraform output -raw cluster_autoscaler_role_arn)
EOF
```

### Step 2.2: Deploy Cluster Autoscaler
```bash
# Get the autoscaler manifest
curl -o cluster-autoscaler.yaml https://raw.githubusercontent.com/kubernetes/autoscaler/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-autodiscover.yaml

# Edit the manifest
# 1. Replace <YOUR CLUSTER NAME> with techitfactory-dev
# 2. Add --balance-similar-node-groups
# 3. Add --skip-nodes-with-system-pods=false

# Or use this command:
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
  labels:
    app: cluster-autoscaler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
    spec:
      serviceAccountName: cluster-autoscaler
      containers:
        - name: cluster-autoscaler
          image: registry.k8s.io/autoscaling/cluster-autoscaler:v1.28.2
          command:
            - ./cluster-autoscaler
            - --v=4
            - --stderrthreshold=info
            - --cloud-provider=aws
            - --skip-nodes-with-local-storage=false
            - --expander=least-waste
            - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/techitfactory-dev
            - --balance-similar-node-groups
            - --skip-nodes-with-system-pods=false
          resources:
            limits:
              cpu: 100m
              memory: 600Mi
            requests:
              cpu: 100m
              memory: 600Mi
          volumeMounts:
            - name: ssl-certs
              mountPath: /etc/ssl/certs/ca-certificates.crt
              readOnly: true
      volumes:
        - name: ssl-certs
          hostPath:
            path: /etc/ssl/certs/ca-bundle.crt
EOF
```

---

## Part 3: Test Autoscaling

### Step 3.1: Deploy High-Demand Workload
```bash
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inflate
spec:
  replicas: 10
  selector:
    matchLabels:
      app: inflate
  template:
    metadata:
      labels:
        app: inflate
    spec:
      containers:
      - name: inflate
        image: public.ecr.aws/eks-distro/kubernetes/pause:3.7
        resources:
          requests:
            cpu: 500m
            memory: 256Mi
EOF
```

### Step 3.2: Watch Autoscaler Logs
```bash
kubectl logs -f deployment/cluster-autoscaler -n kube-system
```

### Step 3.3: Watch Nodes
```bash
watch kubectl get nodes
# Should see new nodes being added
```

### Step 3.4: Cleanup Test
```bash
kubectl delete deployment inflate
# Nodes will scale down after ~10 minutes
```

---

## Verification

### Check Autoscaler Status
```bash
kubectl get pods -n kube-system | grep autoscaler
kubectl logs deployment/cluster-autoscaler -n kube-system | tail -20
```

### Check Node Group Capacity
```bash
aws eks describe-nodegroup \
  --cluster-name techitfactory-dev \
  --nodegroup-name techitfactory-dev-nodes \
  --query "nodegroup.{Min:scalingConfig.minSize,Max:scalingConfig.maxSize,Desired:scalingConfig.desiredSize}"
```

---

## Story Completion Checklist
- [ ] IRSA role for Cluster Autoscaler created
- [ ] Service Account with IRSA annotation
- [ ] Cluster Autoscaler deployed
- [ ] Scale-up tested
- [ ] Scale-down tested
- [ ] Logs show healthy operation

---

## Next: Story 4.4 (Baseline Add-ons)
