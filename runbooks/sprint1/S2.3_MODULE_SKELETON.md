# Sprint 1, Story 2.3: Create Terraform Module Skeleton

## Story Summary
Create reusable Terraform module structure for VPC and EKS that will be implemented in later stories.

**Why:** Modules enable code reuse and consistent patterns across environments.

---

## Prerequisites
- Bootstrap completed (S2.1)
- GitHub OIDC configured (S2.2)
- techitfactory-infra repo

---

## Part 1: Create Folder Structure

### Step 1.0: Create Complete Module Directory Structure
```bash
cd ~/techitfactory/techitfactory-infra

# Create all module directories
mkdir -p modules/vpc
mkdir -p modules/eks
mkdir -p modules/ecr

# Create environment directories
mkdir -p environments/dev
mkdir -p environments/prod

# Verify structure
tree -L 2
# Should show:
# .
# ├── bootstrap/
# ├── environments/
# │   ├── dev/
# │   └── prod/
# └── modules/
#     ├── ecr/
#     ├── eks/
#     └── vpc/
```

---

## Part 2: Create VPC Module Skeleton

### Step 2.1: Create VPC Module Files
```bash
cd ~/techitfactory/techitfactory-infra

# Create empty files first
touch modules/vpc/main.tf
touch modules/vpc/variables.tf
touch modules/vpc/outputs.tf
touch modules/vpc/README.md

# Now populate variables.tf
cat > modules/vpc/variables.tf << 'EOF'
variable "project_name" {
  description = "Project name for resource naming"
  type        = string
}

variable "environment" {
  description = "Environment (dev/prod)"
  type        = string
}

variable "vpc_cidr" {
  description = "CIDR block for VPC"
  type        = string
  default     = "10.0.0.0/16"
}

variable "azs" {
  description = "Availability zones"
  type        = list(string)
  default     = ["ap-south-1a", "ap-south-1b"]
}

variable "public_subnets" {
  description = "CIDR blocks for public subnets"
  type        = list(string)
  default     = ["10.0.1.0/24", "10.0.2.0/24"]
}

variable "private_subnets" {
  description = "CIDR blocks for private subnets"
  type        = list(string)
  default     = ["10.0.10.0/24", "10.0.20.0/24"]
}

variable "single_nat_gateway" {
  description = "Use single NAT gateway (cost optimization)"
  type        = bool
  default     = true
}

variable "enable_s3_endpoint" {
  description = "Enable S3 VPC endpoint"
  type        = bool
  default     = true
}

variable "tags" {
  description = "Additional tags"
  type        = map(string)
  default     = {}
}
EOF
```

### Step 2.2: Create VPC Module Main (Placeholder)
```bash
cat > modules/vpc/main.tf << 'EOF'
# VPC Module - Will be fully implemented in Story 3.1
# This is the skeleton structure

terraform {
  required_version = ">= 1.6.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

locals {
  name = "${var.project_name}-${var.environment}"
}

# TODO: Story 3.1 - Implement VPC
# - VPC with DNS support
# - Public subnets (2 AZs)
# - Private subnets (2 AZs)
# - Internet Gateway
# - Single NAT Gateway (cost-optimized)
# - Route tables
# - S3 VPC Endpoint
EOF
```

### Step 2.3: Create VPC Module Outputs (Placeholder)
```bash
cat > modules/vpc/outputs.tf << 'EOF'
# VPC Module Outputs - Will be populated in Story 3.1

# output "vpc_id" {
#   description = "VPC ID"
#   value       = aws_vpc.main.id
# }

# output "private_subnet_ids" {
#   description = "Private subnet IDs for EKS"
#   value       = aws_subnet.private[*].id
# }

# output "public_subnet_ids" {
#   description = "Public subnet IDs for ALB"
#   value       = aws_subnet.public[*].id
# }
EOF
```

---

## Part 3: Create EKS Module Skeleton

### Step 3.1: Create EKS Module Files
```bash
# Create empty files first
touch modules/eks/main.tf
touch modules/eks/variables.tf
touch modules/eks/outputs.tf
touch modules/eks/README.md

# Now populate variables.tf
cat > modules/eks/variables.tf << 'EOF'
variable "project_name" {
  description = "Project name for resource naming"
  type        = string
}

variable "environment" {
  description = "Environment (dev/prod)"
  type        = string
}

variable "cluster_version" {
  description = "Kubernetes version"
  type        = string
  default     = "1.28"
}

variable "vpc_id" {
  description = "VPC ID for EKS"
  type        = string
}

variable "subnet_ids" {
  description = "Subnet IDs for EKS nodes"
  type        = list(string)
}

variable "node_instance_types" {
  description = "Instance types for node group"
  type        = list(string)
  default     = ["t3.medium"]
}

variable "node_desired_size" {
  description = "Desired number of nodes"
  type        = number
  default     = 2
}

variable "node_min_size" {
  description = "Minimum number of nodes"
  type        = number
  default     = 1
}

variable "node_max_size" {
  description = "Maximum number of nodes"
  type        = number
  default     = 4
}

variable "enable_cluster_autoscaler" {
  description = "Enable cluster autoscaler IRSA"
  type        = bool
  default     = true
}

variable "tags" {
  description = "Additional tags"
  type        = map(string)
  default     = {}
}
EOF
```

### Step 3.2: Create EKS Module Main (Placeholder)
```bash
cat > modules/eks/main.tf << 'EOF'
# EKS Module - Will be fully implemented in Story 4.1
# This is the skeleton structure

terraform {
  required_version = ">= 1.6.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

locals {
  cluster_name = "${var.project_name}-${var.environment}"
}

# TODO: Story 4.1 - Implement EKS
# - EKS Cluster with OIDC issuer
# - Managed Node Group
# - Cluster logging
# - aws-auth ConfigMap for SSO
# - Cluster Autoscaler IRSA
# - EBS CSI Driver IRSA
# - metrics-server
EOF
```

### Step 3.3: Create EKS Module Outputs (Placeholder)
```bash
cat > modules/eks/outputs.tf << 'EOF'
# EKS Module Outputs - Will be populated in Story 4.1

# output "cluster_id" {
#   description = "EKS cluster ID"
#   value       = aws_eks_cluster.main.id
# }

# output "cluster_endpoint" {
#   description = "EKS cluster endpoint"
#   value       = aws_eks_cluster.main.endpoint
# }

# output "cluster_oidc_issuer_url" {
#   description = "OIDC issuer URL for IRSA"
#   value       = aws_eks_cluster.main.identity[0].oidc[0].issuer
# }

# output "cluster_security_group_id" {
#   description = "Security group for cluster"
#   value       = aws_eks_cluster.main.vpc_config[0].cluster_security_group_id
# }
EOF
```

---

## Part 4: Create ECR Module Skeleton

### Step 4.1: Create ECR Module Files
```bash
# Create empty files first
touch modules/ecr/main.tf
touch modules/ecr/variables.tf
touch modules/ecr/outputs.tf
touch modules/ecr/data.tf
touch modules/ecr/README.md

# Populate variables.tf
cat > modules/ecr/variables.tf << 'EOF'
variable "project_name" {
  description = "Project name for resource naming"
  type        = string
}

variable "repositories" {
  description = "List of ECR repository names"
  type        = list(string)
  default     = [
    "frontend",
    "api-gateway",
    "product-service",
    "order-service",
    "cart-service",
    "user-service"
  ]
}

variable "image_tag_mutability" {
  description = "Image tag mutability (MUTABLE or IMMUTABLE)"
  type        = string
  default     = "MUTABLE"
}

variable "scan_on_push" {
  description = "Enable image scanning on push"
  type        = bool
  default     = true
}

variable "lifecycle_policy_count" {
  description = "Number of images to keep per repository"
  type        = number
  default     = 30
}
EOF
```

### Step 4.2: Create ECR Module Main
```bash
cat > modules/ecr/main.tf << 'EOF'
# ECR Module - Repository creation

terraform {
  required_version = ">= 1.6.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

resource "aws_ecr_repository" "main" {
  for_each = toset(var.repositories)

  name                 = "${var.project_name}/${each.value}"
  image_tag_mutability = var.image_tag_mutability

  image_scanning_configuration {
    scan_on_push = var.scan_on_push
  }
}

resource "aws_ecr_lifecycle_policy" "main" {
  for_each   = aws_ecr_repository.main
  repository = each.value.name

  policy = jsonencode({
    rules = [{
      rulePriority = 1
      description  = "Keep last ${var.lifecycle_policy_count} images"
      selection = {
        tagStatus   = "any"
        countType   = "imageCountMoreThan"
        countNumber = var.lifecycle_policy_count
      }
      action = {
        type = "expire"
      }
    }]
  })
}
EOF
```

### Step 4.3: Create ECR Module Outputs and Data
```bash
cat > modules/ecr/data.tf << 'EOF'
data "aws_caller_identity" "current" {}
EOF

cat > modules/ecr/outputs.tf << 'EOF'
output "repository_urls" {
  description = "Map of repository names to URLs"
  value       = { for k, v in aws_ecr_repository.main : k => v.repository_url }
}

output "repository_arns" {
  description = "Map of repository names to ARNs"
  value       = { for k, v in aws_ecr_repository.main : k => v.arn }
}

output "registry_id" {
  description = "ECR Registry ID"
  value       = data.aws_caller_identity.current.account_id
}
EOF
```

---

## Part 5: Create Environment Structure

### Step 5.1: Create Dev Environment Files
```bash
# Create empty files first
touch environments/dev/main.tf
touch environments/dev/variables.tf
touch environments/dev/outputs.tf

# Populate main.tf
cat > environments/dev/main.tf << 'EOF'
# Dev Environment - Will be populated after modules are ready
# This file shows how modules will be used

terraform {
  required_version = ">= 1.6.0"

  # Backend will be configured in Story 3.1
  # backend "s3" {
  #   bucket         = "<from-bootstrap>"
  #   key            = "environments/dev/terraform.tfstate"
  #   region         = "ap-south-1"
  #   encrypt        = true
  #   dynamodb_table = "<from-bootstrap>"
  # }

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = "ap-south-1"

  default_tags {
    tags = {
      Environment = "dev"
      Project     = "TechITFactory"
      ManagedBy   = "Terraform"
    }
  }
}

# VPC Module (Story 3.1)
# module "vpc" {
#   source = "../../modules/vpc"
#
#   project_name       = "techitfactory"
#   environment        = "dev"
#   single_nat_gateway = true
# }

# EKS Module (Story 4.1)
# module "eks" {
#   source = "../../modules/eks"
#
#   project_name = "techitfactory"
#   environment  = "dev"
#   vpc_id       = module.vpc.vpc_id
#   subnet_ids   = module.vpc.private_subnet_ids
# }
EOF
```

### Step 5.2: Create Dev Environment Variables
```bash
cat > environments/dev/variables.tf << 'EOF'
# Dev Environment Variables

variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "ap-south-1"
}
EOF
```

### Step 5.3: Create Prod Environment Placeholder
```bash
touch environments/prod/main.tf
touch environments/prod/variables.tf
touch environments/prod/outputs.tf
cat > environments/prod/main.tf << 'EOF'
# Prod Environment - Placeholder
# Similar to dev but with different configurations:
# - Multiple NAT gateways for HA
# - Larger node sizes
# - Different instance counts

# Will be implemented after dev is validated
EOF
```

---

## Part 6: Create Module Documentation

### Step 6.1: Update VPC Module README
```bash
cat > modules/vpc/README.md << 'EOF'
# VPC Module

Creates a production-ready VPC with public/private subnets.

## Features
- Multi-AZ deployment (2 AZs)
- Public subnets for ALB
- Private subnets for EKS nodes
- Single NAT Gateway (cost-optimized for dev)
- S3 VPC Endpoint

## Usage

```hcl
module "vpc" {
  source = "../../modules/vpc"

  project_name       = "techitfactory"
  environment        = "dev"
  vpc_cidr           = "10.0.0.0/16"
  single_nat_gateway = true
  enable_s3_endpoint = true
}
```

## Inputs

| Name | Description | Type | Default |
|------|-------------|------|---------|
| project_name | Project name | string | - |
| environment | Environment | string | - |
| vpc_cidr | VPC CIDR | string | 10.0.0.0/16 |
| single_nat_gateway | Use single NAT | bool | true |

## Outputs

| Name | Description |
|------|-------------|
| vpc_id | VPC ID |
| private_subnet_ids | Private subnet IDs |
| public_subnet_ids | Public subnet IDs |
EOF
```

### Step 6.2: Update EKS Module README
```bash
cat > modules/eks/README.md << 'EOF'
# EKS Module

Creates a production-ready EKS cluster with managed node groups.

## Features
- EKS with OIDC for IRSA
- Managed Node Group (t3.medium)
- Cluster Autoscaler support
- EBS CSI Driver
- SSO access via aws-auth

## Usage

```hcl
module "eks" {
  source = "../../modules/eks"

  project_name  = "techitfactory"
  environment   = "dev"
  vpc_id        = module.vpc.vpc_id
  subnet_ids    = module.vpc.private_subnet_ids
  
  node_desired_size = 2
  node_min_size     = 1
  node_max_size     = 4
}
```

## Inputs

| Name | Description | Type | Default |
|------|-------------|------|---------|
| project_name | Project name | string | - |
| cluster_version | K8s version | string | 1.28 |
| node_instance_types | Instance types | list | t3.medium |

## Outputs

| Name | Description |
|------|-------------|
| cluster_id | EKS cluster ID |
| cluster_endpoint | API endpoint |
| cluster_oidc_issuer_url | OIDC URL for IRSA |
EOF
```

---

## Part 7: Commit and Push

### Step 7.1: Stage and Commit
```bash
cd ~/techitfactory/techitfactory-infra
git checkout -b feature/module-skeleton

git add modules/
git add environments/

git commit -m "Add Terraform module skeletons for VPC and EKS"
```

### Step 7.2: Push and Create PR
```bash
git push origin feature/module-skeleton

gh pr create --title "Epic 2: Add Terraform module skeletons" \
  --body "Creates VPC and EKS module structure with variables, placeholders, and documentation."
```

### Step 7.3: Merge
```bash
gh pr merge --squash
git checkout main
git pull
```

---

## Verification

### Check Module Structure
```bash
tree modules/
# Should show:
# modules/
# ├── eks/
# │   ├── main.tf
# │   ├── outputs.tf
# │   ├── README.md
# │   └── variables.tf
# └── vpc/
#     ├── main.tf
#     ├── outputs.tf
#     ├── README.md
#     └── variables.tf
```

### Validate Modules
```bash
cd modules/vpc
terraform init
terraform validate

cd ../eks
terraform init
terraform validate
```

---

## Story Completion Checklist
- [ ] modules/vpc/ has variables.tf, main.tf, outputs.tf, README.md
- [ ] modules/eks/ has variables.tf, main.tf, outputs.tf, README.md
- [ ] environments/dev/main.tf skeleton created
- [ ] environments/prod/main.tf placeholder created
- [ ] terraform validate passes for all modules
- [ ] Changes committed and pushed

---

## Next: Epic 3 - Networking (Story 3.1)
The VPC module will be fully implemented in Story 3.1.
